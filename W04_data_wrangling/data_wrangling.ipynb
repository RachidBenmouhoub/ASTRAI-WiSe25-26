{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Data Wrangling</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../image/wrangling_DALLE.jpeg\" width=30% align=\"right\" style=\"in-line\">\n",
    "\n",
    ">*80% of data wrangling is spent cleaning the data.*\n",
    ">\n",
    ">*The other 20% is spent complaining about cleaning the data.*\n",
    ">\n",
    ">â€” Source: [Kyle Bradbury & Nick Eubank](https://www.practicaldatascience.org/notebooks/class_3/week_3/20_cleaning_identifying.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Learning goals\n",
    "\n",
    "1. Be able to perform web scraping across multiple pages.\n",
    "2. Be able to load, explore, and understand the structure of datasets using Python.\n",
    "3. Become familiar with common data wrangling tasks, including handling missing values, merging datasets, filtering, and sorting data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-01T08:33:09.252271Z",
     "start_time": "2022-04-01T08:33:09.160011Z"
    }
   },
   "source": [
    "## Agenda\n",
    "\n",
    "1. [Review: web scraping](#1)\n",
    "2. [Data wrangling](#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1\"></a>\n",
    "## Agenda 1. Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1F4DD; **<font color=dodgerblue>FROM LAST WEEK: </font>** Here is an example project. We would like to find out what the European Union has done recently (let's say since 2024) to advance sustainable mobility and transport. One possible data source is the news we just scraped, but we need more information other than the title of the news.\n",
    "\n",
    "So now please write some code to collect **the date, the title, the short description, the news type, and the link to the full text** of all news in 2024. Save the data to a **csv** file.\n",
    "\n",
    "Here are some tips:\n",
    "1. How many pages do you need to scrape? Observe how the web addresses change between the first page and the second.\n",
    "2. Remember we have talked about **avoid overloading servers** in ethics. Make sure to use `time.sleep()`.\n",
    "\n",
    "If you would like to challenge yourself, see if you can scrape the full text (not the short description) of the news. Try with one or two pieces of news would be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:08.732694Z",
     "start_time": "2025-11-04T15:16:08.149536Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Send an HTTP request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:37:23.915938Z",
     "start_time": "2025-11-04T14:37:23.798776Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://transport.ec.europa.eu/news-events/news_en?page=0\"\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:37:27.563077Z",
     "start_time": "2025-11-04T14:37:27.551319Z"
    }
   },
   "outputs": [],
   "source": [
    "print(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Parse the HTML content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:37:33.931078Z",
     "start_time": "2025-11-04T14:37:33.893426Z"
    }
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T12:16:55.948407Z",
     "start_time": "2025-10-29T12:16:55.940496Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(soup)\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Locate the HTML elements containing the desired data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chrome: `View` -> `Developer` -> `Inspect Elements`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:42:44.309767Z",
     "start_time": "2025-11-04T14:42:44.296124Z"
    }
   },
   "outputs": [],
   "source": [
    "news = soup.find_all(\"article\", class_=\"ecl-content-item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:42:45.418612Z",
     "start_time": "2025-11-04T14:42:45.403917Z"
    }
   },
   "outputs": [],
   "source": [
    "print(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:42:53.303222Z",
     "start_time": "2025-11-04T14:42:53.286592Z"
    }
   },
   "outputs": [],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Extract data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T12:17:11.931629Z",
     "start_time": "2025-10-29T12:17:11.915564Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for item in news:\n",
    "    date = item.time.attrs['datetime']\n",
    "    title = item.find(\"a\", class_=\"ecl-link ecl-link--standalone\").get_text()\n",
    "    desc = item.find(\"div\", class_=\"ecl-content-block__description\").get_text()\n",
    "    news_type = item.find(\"li\", class_=\"ecl-content-block__primary-meta-item\").get_text()\n",
    "    link = item.find(\"a\", class_=\"ecl-link ecl-link--standalone\", href=True)[\"href\"]\n",
    "    print(date,title,desc)\n",
    "    print(news_type)\n",
    "    print(link)\n",
    "    print(\"=====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news[0].time # the <time> element of the first article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape multiple pages, we need to observe how the web addresses change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T14:35:13.657727Z",
     "start_time": "2025-10-29T14:35:13.652226Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#page_number = range(12,22) # year 2024. your number could be different\n",
    "page_number = range(0,13) # year 2025\n",
    "stem = \"https://transport.ec.europa.eu/news-events/news_en?page=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T14:35:16.695608Z",
     "start_time": "2025-10-29T14:35:16.689723Z"
    }
   },
   "outputs": [],
   "source": [
    "#csv_filename = \"news2024.csv\" # give the csv file a name\n",
    "csv_filename = \"news2025.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T14:35:41.425539Z",
     "start_time": "2025-10-29T14:35:19.033779Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in page_number: # loop over all the pages\n",
    "    url = stem + str(i)\n",
    "    print(url)\n",
    "    \n",
    "    page = requests.get(url) # send the request\n",
    "    soup = BeautifulSoup(page.content, 'html.parser') # parse the content\n",
    "    news = soup.find_all(\"article\", class_=\"ecl-content-item\") # locate all the news\n",
    "    \n",
    "    for item in news: # loop over each article\n",
    "        try: # use try except to skip error e.g., NoneType object - empty elements\n",
    "            date = item.time.attrs['datetime']\n",
    "        except (AttributeError, KeyError, TypeError) as e:\n",
    "            date = \"\"\n",
    "            print(f\"Error extracting date: {e}\")\n",
    "            print(item)\n",
    "            print(\"====\")\n",
    "        try:\n",
    "            title = item.find(\"a\", class_=\"ecl-link ecl-link--standalone\").get_text()\n",
    "        except AttributeError as e:\n",
    "            title = \"\"\n",
    "            print(f\"Error extracting title: {e}\")\n",
    "            print(item)\n",
    "            print(\"====\")\n",
    "        try:\n",
    "            desc = item.find(\"div\", class_=\"ecl-content-block__description\").get_text()\n",
    "        except AttributeError as e:\n",
    "            desc = \"\"\n",
    "            print(f\"Error extracting description: {e}\")\n",
    "            print(item)\n",
    "            print(\"====\")\n",
    "        try:\n",
    "            news_type = item.find(\"li\", class_=\"ecl-content-block__primary-meta-item\").get_text()\n",
    "        except AttributeError as e:\n",
    "            news_type = \"\"\n",
    "            print(f\"Error extracting news type: {e}\")\n",
    "            print(item)\n",
    "            print(\"====\")\n",
    "        try:\n",
    "            link = item.find(\"a\", class_=\"ecl-link ecl-link--standalone\", href=True)[\"href\"]\n",
    "        except (AttributeError, TypeError) as e:\n",
    "            link = \"\"\n",
    "            print(f\"Error extracting link: {e}\")\n",
    "            print(item)\n",
    "            print(\"====\")\n",
    "        csv.writer(open(csv_filename, \"a\", encoding=\"utf-8\")).writerow([date, title, desc, news_type, link])\n",
    "        \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got 2 errors running the above cell (for year 2025). It is okay. I have saved the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T14:54:06.103918Z",
     "start_time": "2025-11-04T14:54:06.090241Z"
    }
   },
   "outputs": [],
   "source": [
    "# the error output\n",
    "\n",
    "<article class=\"ecl-content-item\"><div class=\"ecl-content-block ecl-content-item__content-block\" data-ecl-auto-init=\"ContentBlock\" data-ecl-content-block=\"\"><ul class=\"ecl-content-block__primary-meta-container\"><li class=\"ecl-content-block__primary-meta-item\">News article</li><li class=\"ecl-content-block__primary-meta-item\"><time datetime=\"2025-08-05T12:00:00Z\">5 August 2025</time></li></ul><div class=\"ecl-content-block__title\" data-ecl-title-link=\"\"><a class=\"ecl-link ecl-link--standalone ecl-link--icon\" href=\"https://aa293.referrals.selectminds.com/eu-rail/jobs/communication-and-ex-post-audit-officer-148\"><span class=\"ecl-link__label\">Vacancy notice: communication and ex-post audit officer</span><span class=\"wt-icon--external ecl-icon ecl-icon--2xs ecl-link__icon ecl-icon--external\"></span></a></div><div class=\"ecl-content-block__description\"><p>The Europe's Rail Joint Undertaking (EU-RAIL), based in Brussels is establishing a reserve list for a post of communication and ex-post audit officer (temporary agent, grade AD5)</p></div><ul class=\"ecl-content-block__secondary-meta-container\"><li class=\"ecl-content-block__secondary-meta-item\"><span class=\"wt-icon--clock ecl-icon ecl-icon--s ecl-content-block__secondary-meta-icon ecl-icon--clock\"></span><span class=\"ecl-content-block__secondary-meta-label\">1 min read</span></li></ul></div></article>\n",
    "====\n",
    "\n",
    "<article class=\"ecl-content-item\"><div class=\"ecl-content-block ecl-content-item__content-block\" data-ecl-auto-init=\"ContentBlock\" data-ecl-content-block=\"\"><ul class=\"ecl-content-block__primary-meta-container\"><li class=\"ecl-content-block__primary-meta-item\">News article</li><li class=\"ecl-content-block__primary-meta-item\"><time datetime=\"2025-08-05T12:00:00Z\">5 August 2025</time></li></ul><div class=\"ecl-content-block__title\" data-ecl-title-link=\"\"><a class=\"ecl-link ecl-link--standalone ecl-link--icon\" href=\"https://aa293.referrals.selectminds.com/eu-rail/jobs/communication-and-ex-post-audit-officer-148\"><span class=\"ecl-link__label\">Vacancy notice: communication and ex-post audit officer</span><span class=\"wt-icon--external ecl-icon ecl-icon--2xs ecl-link__icon ecl-icon--external\"></span></a></div><div class=\"ecl-content-block__description\"><p>The Europe's Rail Joint Undertaking (EU-RAIL), based in Brussels is establishing a reserve list for a post of communication and ex-post audit officer (temporary agent, grade AD5)</p></div><ul class=\"ecl-content-block__secondary-meta-container\"><li class=\"ecl-content-block__secondary-meta-item\"><span class=\"wt-icon--clock ecl-icon ecl-icon--s ecl-content-block__secondary-meta-icon ecl-icon--clock\"></span><span class=\"ecl-content-block__secondary-meta-label\">1 min read</span></li></ul></div></article>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## Agenda 2. Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data wrangling is the process of converting raw data into a usable form. It typically involves examining the data, handling missing values, cleaning, and transforming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T13:11:43.552479Z",
     "start_time": "2024-10-04T13:11:43.536199Z"
    }
   },
   "source": [
    "We start by loading our datasets and inspecting them to get a better sense of their structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:12.552987Z",
     "start_time": "2025-11-04T15:16:12.533750Z"
    }
   },
   "outputs": [],
   "source": [
    "news2025 = pd.read_csv(\"news2025.csv\", encoding=\"utf-8\", names=[\"date\", \"title\", \"desc\", \"type\", \"link\"]) # import csv with column names\n",
    "news2024 = pd.read_csv(\"news2024.csv\", encoding=\"utf-8\", names=[\"date\", \"title\", \"desc\", \"type\", \"link\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:15.074591Z",
     "start_time": "2025-11-04T15:16:15.053273Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "news2024.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:15.629613Z",
     "start_time": "2025-11-04T15:16:15.618329Z"
    }
   },
   "outputs": [],
   "source": [
    "len(news2024) # check the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:16.312767Z",
     "start_time": "2025-11-04T15:16:16.301346Z"
    }
   },
   "outputs": [],
   "source": [
    "news2024.shape # check the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:16.889829Z",
     "start_time": "2025-11-04T15:16:16.871973Z"
    }
   },
   "outputs": [],
   "source": [
    "news2024.info() # summarize by the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:17.427203Z",
     "start_time": "2025-11-04T15:16:17.420326Z"
    }
   },
   "outputs": [],
   "source": [
    "# news2024.describe() # useful for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:18.088058Z",
     "start_time": "2025-11-04T15:16:18.076939Z"
    }
   },
   "outputs": [],
   "source": [
    "type(news2024.date.iloc[0]) # check the data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:18.643372Z",
     "start_time": "2025-11-04T15:16:18.632736Z"
    }
   },
   "outputs": [],
   "source": [
    "news2024.type.unique() # check the unique values of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:19.182586Z",
     "start_time": "2025-11-04T15:16:19.169795Z"
    }
   },
   "outputs": [],
   "source": [
    "news2024.type.value_counts() # check each value's number of occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:20.360750Z",
     "start_time": "2025-11-04T15:16:20.345183Z"
    }
   },
   "outputs": [],
   "source": [
    "news2024.isnull().sum() # identify missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:20.968198Z",
     "start_time": "2025-11-04T15:16:20.952904Z"
    }
   },
   "outputs": [],
   "source": [
    "news2025.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:21.637091Z",
     "start_time": "2025-11-04T15:16:21.619337Z"
    }
   },
   "outputs": [],
   "source": [
    "news2025[news2025.title.isnull()] # pinpoint which rows have missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:22.224546Z",
     "start_time": "2025-11-04T15:16:22.209261Z"
    }
   },
   "outputs": [],
   "source": [
    "#news2025.title.isnull() # this is a mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:22.769024Z",
     "start_time": "2025-11-04T15:16:22.751254Z"
    }
   },
   "outputs": [],
   "source": [
    "news2025[news2025.link.isnull()] # check again by \"link\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values can often skew analyses or create errors during analysis. Here are some common strategies for handling missing values:\n",
    "\n",
    "- Manually review and fix the missing data (if possible)\n",
    "- Remove missing data e.g., drop rows\n",
    "- Impute missing data e.g., replace with the mean (for numerical data)\n",
    "- Fill with a specific value e.g., replace with \"unknown\" or \"NA\"\n",
    "- Predictive imputation e.g., use machine learning models to predict missing values based on other features\n",
    "- Leave as missing\n",
    "\n",
    "For our example, we choose the first option because we have access to the original data source. Let's go back to the previous error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x1F4A1; **Markdown**: Markdown is a markup language. It can be used as a text-to-HTML conversion tool. Read more on Jupyter [Markdown cells](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html). It can help us read the error messages and fix the missing values. Below is a direct copy & paste of the [error messages](#error) (in a Markedown cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the error output\n",
    "\n",
    "<article class=\"ecl-content-item\"><div class=\"ecl-content-block ecl-content-item__content-block\" data-ecl-auto-init=\"ContentBlock\" data-ecl-content-block=\"\"><ul class=\"ecl-content-block__primary-meta-container\"><li class=\"ecl-content-block__primary-meta-item\">News article</li><li class=\"ecl-content-block__primary-meta-item\"><time datetime=\"2025-08-05T12:00:00Z\">5 August 2025</time></li></ul><div class=\"ecl-content-block__title\" data-ecl-title-link=\"\"><a class=\"ecl-link ecl-link--standalone ecl-link--icon\" href=\"https://aa293.referrals.selectminds.com/eu-rail/jobs/communication-and-ex-post-audit-officer-148\"><span class=\"ecl-link__label\">Vacancy notice: communication and ex-post audit officer</span><span class=\"wt-icon--external ecl-icon ecl-icon--2xs ecl-link__icon ecl-icon--external\"></span></a></div><div class=\"ecl-content-block__description\"><p>The Europe's Rail Joint Undertaking (EU-RAIL), based in Brussels is establishing a reserve list for a post of communication and ex-post audit officer (temporary agent, grade AD5)</p></div><ul class=\"ecl-content-block__secondary-meta-container\"><li class=\"ecl-content-block__secondary-meta-item\"><span class=\"wt-icon--clock ecl-icon ecl-icon--s ecl-content-block__secondary-meta-icon ecl-icon--clock\"></span><span class=\"ecl-content-block__secondary-meta-label\">1 min read</span></li></ul></div></article>\n",
    "====\n",
    "\n",
    "<article class=\"ecl-content-item\"><div class=\"ecl-content-block ecl-content-item__content-block\" data-ecl-auto-init=\"ContentBlock\" data-ecl-content-block=\"\"><ul class=\"ecl-content-block__primary-meta-container\"><li class=\"ecl-content-block__primary-meta-item\">News article</li><li class=\"ecl-content-block__primary-meta-item\"><time datetime=\"2025-08-05T12:00:00Z\">5 August 2025</time></li></ul><div class=\"ecl-content-block__title\" data-ecl-title-link=\"\"><a class=\"ecl-link ecl-link--standalone ecl-link--icon\" href=\"https://aa293.referrals.selectminds.com/eu-rail/jobs/communication-and-ex-post-audit-officer-148\"><span class=\"ecl-link__label\">Vacancy notice: communication and ex-post audit officer</span><span class=\"wt-icon--external ecl-icon ecl-icon--2xs ecl-link__icon ecl-icon--external\"></span></a></div><div class=\"ecl-content-block__description\"><p>The Europe's Rail Joint Undertaking (EU-RAIL), based in Brussels is establishing a reserve list for a post of communication and ex-post audit officer (temporary agent, grade AD5)</p></div><ul class=\"ecl-content-block__secondary-meta-container\"><li class=\"ecl-content-block__secondary-meta-item\"><span class=\"wt-icon--clock ecl-icon ecl-icon--s ecl-content-block__secondary-meta-icon ecl-icon--clock\"></span><span class=\"ecl-content-block__secondary-meta-label\">1 min read</span></li></ul></div></article>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:25.093003Z",
     "start_time": "2025-11-04T15:16:25.079564Z"
    }
   },
   "outputs": [],
   "source": [
    "news2025.title.iloc[36]# the first missing title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:25.715999Z",
     "start_time": "2025-11-04T15:16:25.707965Z"
    }
   },
   "outputs": [],
   "source": [
    "# write the title to the cell\n",
    "news2025.iloc[36].title = \"Vacancy notice: communication and ex-post audit officer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:29.304030Z",
     "start_time": "2025-11-04T15:16:29.285172Z"
    }
   },
   "outputs": [],
   "source": [
    "news2025[news2025.title.isnull()] # check missing titles again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:32.977744Z",
     "start_time": "2025-11-04T15:16:32.965507Z"
    }
   },
   "outputs": [],
   "source": [
    "# do the same for the missing link\n",
    "news2025.iloc[36].link = \"https://aa293.referrals.selectminds.com/eu-rail/jobs/communication-and-ex-post-audit-officer-148\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:43.455481Z",
     "start_time": "2025-11-04T15:16:43.439914Z"
    }
   },
   "outputs": [],
   "source": [
    "news2025.isnull().sum() # check again. no more missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways of merging datasets. Check this [documentation](https://pandas.pydata.org/docs/user_guide/merging.html). Let's combine our two datasets into one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:46.021282Z",
     "start_time": "2025-11-04T15:16:46.011624Z"
    }
   },
   "outputs": [],
   "source": [
    "news = pd.concat([news2024, news2025], ignore_index=True) # concatenate and re-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:46.517313Z",
     "start_time": "2025-11-04T15:16:46.495123Z"
    }
   },
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:47.106761Z",
     "start_time": "2025-11-04T15:16:47.095572Z"
    }
   },
   "outputs": [],
   "source": [
    "news.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing is missing. However, we might have created duplicated values when merging datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:49.115525Z",
     "start_time": "2025-11-04T15:16:49.092962Z"
    }
   },
   "outputs": [],
   "source": [
    "news[news.duplicated()] # identify duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:49.602212Z",
     "start_time": "2025-11-04T15:16:49.588111Z"
    }
   },
   "outputs": [],
   "source": [
    "news.duplicated() # returns a Boolean Series indicating whether each row is a duplicate of a previous row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:50.299856Z",
     "start_time": "2025-11-04T15:16:50.287656Z"
    }
   },
   "outputs": [],
   "source": [
    "news = news.drop_duplicates() # drop duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:50.924893Z",
     "start_time": "2025-11-04T15:16:50.904721Z"
    }
   },
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to fix the date using [`pandas.to_datetime` function](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:52.229948Z",
     "start_time": "2025-11-04T15:16:52.215611Z"
    }
   },
   "outputs": [],
   "source": [
    "type(news.date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:52.789621Z",
     "start_time": "2025-11-04T15:16:52.768587Z"
    }
   },
   "outputs": [],
   "source": [
    "news.loc[:, \"date\"] = pd.to_datetime(news.date) # change the data type to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:53.396909Z",
     "start_time": "2025-11-04T15:16:53.383598Z"
    }
   },
   "outputs": [],
   "source": [
    "type(news.date[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:54.019236Z",
     "start_time": "2025-11-04T15:16:53.998613Z"
    }
   },
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:54.682967Z",
     "start_time": "2025-11-04T15:16:54.669814Z"
    }
   },
   "outputs": [],
   "source": [
    "news = news.sort_values(by=\"date\", ascending=False) # sort the rows by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:55.375294Z",
     "start_time": "2025-11-04T15:16:55.356002Z"
    }
   },
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:55.974799Z",
     "start_time": "2025-11-04T15:16:55.959949Z"
    }
   },
   "outputs": [],
   "source": [
    "news['date'] = pd.to_datetime(news['date']) # make sure the 'date' column is of datetime type\n",
    "news = news[news['date'].dt.year!=2023] # remove news from 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:56.668563Z",
     "start_time": "2025-11-04T15:16:56.648783Z"
    }
   },
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:57.217454Z",
     "start_time": "2025-11-04T15:16:57.203681Z"
    }
   },
   "outputs": [],
   "source": [
    "news.type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:16:58.044234Z",
     "start_time": "2025-11-04T15:16:58.026788Z"
    }
   },
   "outputs": [],
   "source": [
    "news[news.type==\"Press release\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:17:00.544423Z",
     "start_time": "2025-11-04T15:17:00.536097Z"
    }
   },
   "outputs": [],
   "source": [
    "#news[news.type==\"General publications\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's only keep the news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:17:01.764121Z",
     "start_time": "2025-11-04T15:17:01.756012Z"
    }
   },
   "outputs": [],
   "source": [
    "news = news[news.type==\"News article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:17:02.498317Z",
     "start_time": "2025-11-04T15:17:02.489162Z"
    }
   },
   "outputs": [],
   "source": [
    "news = news.reset_index(drop=True) # reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:17:03.431561Z",
     "start_time": "2025-11-04T15:17:03.410066Z"
    }
   },
   "outputs": [],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:17:04.650330Z",
     "start_time": "2025-11-04T15:17:04.641574Z"
    }
   },
   "outputs": [],
   "source": [
    "#news = news[[\"date\", \"title\", \"desc\"]] # new df with selected columns (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-04T15:17:06.725133Z",
     "start_time": "2025-11-04T15:17:06.703326Z"
    }
   },
   "outputs": [],
   "source": [
    "news.to_csv(\"news_clean.csv\", index=False) # save to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x2753;**<font color=cornflowerblue>QUESTION: </font>** What are the common tasks involved in data wrangling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#x270A; **<font color=firebrick>DO THIS: </font>** Here are two options to practice what we've learned and to further develop your data skills:\n",
    "\n",
    "1. Do some data wrangling on the data you scraped last week.\n",
    "2. Explore the existing `news_clean.csv` dataset. What research question can it answer? Using what methods/tools?\n",
    "\n",
    "Feel free to pick one task or do both. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-05T10:07:13.004543Z",
     "start_time": "2024-10-05T10:07:12.993255Z"
    }
   },
   "outputs": [],
   "source": [
    "# put your code here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "### Congratulations, we are done!\n",
    "\n",
    "This notebook is written by [Meng Cai](https://www.verkehr.tu-darmstadt.de/vv/das_institut_ivv/team_ivv/wissenschaftliche_mitarbeiter_doktoranden/meng_cai/standardseite_204.de.jsp), Technical University of Darmstadt. This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\">Creative Commons Attribution-NonCommercial 4.0 International License</a>.\n",
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc/4.0/88x31.png\" /></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
